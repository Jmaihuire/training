{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of TFRecords creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data into numpy arrays\n",
    "(X_trn, y_trn), (X_tst, y_tst) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_trn = np.reshape(X_trn, [X_trn.shape[0], 28, 28, 1])\n",
    "X_tst = np.reshape(X_tst, [X_tst.shape[0], 28, 28, 1])\n",
    "print(X_trn.shape)\n",
    "print(y_trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(values):\n",
    "    if not isinstance(values, (tuple, list)):\n",
    "        values = [values]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "\n",
    "def _bytes_feature(values):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_arrays_to_tfrecord(images, labels, output_file):\n",
    "    \"\"\"Converts a file to TFRecords.\"\"\"\n",
    "    print('Generating %s' % output_file)\n",
    "    with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "        for image, label in zip(images, labels):\n",
    "            example = tf.train.Example(features=tf.train.Features(\n",
    "                feature={\n",
    "                        'image': _bytes_feature(image.tobytes()),\n",
    "                        'label': _int64_feature(label)\n",
    "                        }))\n",
    "            record_writer.write(example.SerializeToString())\n",
    "    print('Done!')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating /tmp/trn.tfrecord\n",
      "Done!\n",
      "Generating /tmp/trn.tfrecord\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "trn_tfrecords_file = '/tmp/trn.tfrecord'\n",
    "convert_arrays_to_tfrecord(X_trn, y_trn, trn_tfrecords_file)\n",
    "\n",
    "tst_tfrecords_file = '/tmp/tst.tfrecord'\n",
    "convert_arrays_to_tfrecord(X_tst, y_tst, trn_tfrecords_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the parser and the input_fn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH = 1\n",
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "\n",
    "def mnist_parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "    # Custom preprocessing.\n",
    "    #image = self.preprocess(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(TFfilenames, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(TFfilenames)\n",
    "    dataset = dataset.map(mnist_parser, num_parallel_calls=1)\n",
    "    \n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.cache().shuffle(buffer_size=1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Generate iterator and return the next elements of the iterator\n",
    "    # in 1.6 and above you can pass directly the dataset and the estimator build internaly the iterator.\n",
    "    (images, labels) = dataset.make_one_shot_iterator().get_next()\n",
    "    return (images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_fn(TFfilenames, batch_size):\n",
    "    # ... Pending\n",
    "    return (images, labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our input pipeline. Pin it to the CPU so that the GPU can be reserved\n",
    "# for forward and backwards propogation.\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 32\n",
    "with tf.device('/cpu:0'):\n",
    "    train_images, train_labels = train_input_fn(trn_tfrecords_file, batch_size)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the tfrecord content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 5 9 5 4 6 1 1 2 0 6 3 7 0 8 4 4 1 2 3 8 8 2 1 4 0 2 8 3 4 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+IGgCD8Q1P8DSQ5dkvfcK0gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check that all is correct\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    with tf.contrib.slim.queues.QueueRunners(sess):\n",
    "        sample_images, sample_labels = sess.run([train_images, train_labels])\n",
    "\n",
    "plt.imshow(sample_images[0,:,:,0], cmap='gray')\n",
    "print(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a default estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.models.Model):\n",
    "  \"\"\"Model to recognize digits in the MNIST dataset.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "        \n",
    "    # Define layers to use in the model\n",
    "    self._input_shape = [-1, 28, 28, 1]\n",
    "\n",
    "    self.conv1 = tf.layers.Conv2D(32, 5, padding='same', activation=tf.nn.relu)\n",
    "    self.max_pool2d = tf.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
    "    \n",
    "    self.conv2 = tf.layers.Conv2D(64, 5, padding='same', activation=tf.nn.relu)\n",
    "    \n",
    "    self.fc1 = tf.layers.Dense(1024, activation=tf.nn.relu)\n",
    "    self.dropout = tf.layers.Dropout(0.4)\n",
    "    \n",
    "    self.fc2 = tf.layers.Dense(10)\n",
    "\n",
    "    \n",
    "  def __call__(self, inputs, training):\n",
    "    \"\"\"Add operations to classify a batch of input images.\n",
    "    Args:\n",
    "      inputs: A Tensor representing a batch of input images.\n",
    "      training: A boolean. Set to True to add operations required only when\n",
    "        training the classifier.\n",
    "    Returns:\n",
    "      A logits Tensor with shape [<batch_size>, 10].\n",
    "    \"\"\"\n",
    "    y = tf.reshape(inputs, self._input_shape)\n",
    "    y = self.conv1(y)\n",
    "    y = self.max_pool2d(y)\n",
    "    y = self.conv2(y)\n",
    "    y = self.max_pool2d(y)\n",
    "    y = tf.layers.flatten(y)\n",
    "    y = self.fc1(y)\n",
    "    y = self.dropout(y, training=training)\n",
    "    return self.fc2(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "\n",
    "# Define the model_function compatible with tf.estimators\n",
    "def model_fn(features, labels, mode, params):\n",
    "    \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "    image = features\n",
    "    if isinstance(image, dict):\n",
    "        image = features['image']\n",
    "    \n",
    "    # Instanciate the model\n",
    "    model = Model()\n",
    "    \n",
    "\n",
    "    # Train step\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "        logits = model(image, training=True)\n",
    "    \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=tf.argmax(logits, axis=1))\n",
    "        tf.identity(accuracy[1], name='train_accuracy')\n",
    "    \n",
    "        tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.TRAIN,\n",
    "            loss=loss,\n",
    "            train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))\n",
    "\n",
    "\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        logits = model(image, training=False)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.EVAL,\n",
    "            loss=loss,\n",
    "            eval_metric_ops={\n",
    "                'accuracy':\n",
    "                    tf.metrics.accuracy(\n",
    "                        labels=labels,\n",
    "                        predictions=tf.argmax(logits, axis=1)),\n",
    "            })\n",
    "\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        logits = model(image, training=False)\n",
    "        predictions = {\n",
    "            'classes': tf.argmax(logits, axis=1),\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=tf.estimator.ModeKeys.PREDICT,\n",
    "            predictions=predictions,\n",
    "            export_outputs={\n",
    "                'classify': tf.estimator.export.PredictOutput(predictions)\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc51817c400>, '_task_id': 0, '_save_summary_steps': 100, '_service': None, '_tf_random_seed': None, '_log_step_count_steps': 100, '_model_dir': '/tmp/mnist', '_is_chief': True, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist/model.ckpt-100\n",
      "INFO:tensorflow:Saving checkpoints for 101 into /tmp/mnist/model.ckpt.\n",
      "INFO:tensorflow:train_accuracy = 0.84375\n",
      "INFO:tensorflow:loss = 1.00334, step = 101\n",
      "INFO:tensorflow:train_accuracy = 0.84375 (0.198 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.875 (0.059 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.851562 (0.061 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.83125 (0.057 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.838542 (0.056 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.834821 (0.058 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.832031 (0.058 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.840278 (0.062 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.85 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.794\n",
      "INFO:tensorflow:train_accuracy = 0.84375 (0.060 sec)\n",
      "INFO:tensorflow:loss = 1.26865, step = 201 (0.732 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.851562 (0.057 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.848558 (0.055 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.852679 (0.059 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.8625 (0.065 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.857422 (0.065 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.862132 (0.063 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.864583 (0.063 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.866776 (0.064 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.867188 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.047\n",
      "INFO:tensorflow:train_accuracy = 0.870536 (0.071 sec)\n",
      "INFO:tensorflow:loss = 0.55366, step = 301 (0.630 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.875 (0.057 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.879076 (0.059 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.880208 (0.065 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.8825 (0.067 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.887019 (0.068 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.888889 (0.067 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.891741 (0.073 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.894397 (0.069 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.891667 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.315\n",
      "INFO:tensorflow:train_accuracy = 0.893145 (0.043 sec)\n",
      "INFO:tensorflow:loss = 0.539735, step = 401 (0.612 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.892578 (0.043 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.892992 (0.044 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.894301 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.895536 (0.041 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.895833 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.896959 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.899671 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.89984 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.9 (0.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.879\n",
      "INFO:tensorflow:train_accuracy = 0.902439 (0.042 sec)\n",
      "INFO:tensorflow:loss = 0.0332606, step = 501 (0.403 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.903274 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.903343 (0.035 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.903409 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.902083 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.902853 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.904255 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.905599 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.90625 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.9075 (0.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.028\n",
      "INFO:tensorflow:train_accuracy = 0.90625 (0.039 sec)\n",
      "INFO:tensorflow:loss = 0.376897, step = 601 (0.377 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.907452 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.908019 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.907986 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.909659 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.910156 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.911184 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.912177 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.912606 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.913542 (0.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.442\n",
      "INFO:tensorflow:train_accuracy = 0.913934 (0.036 sec)\n",
      "INFO:tensorflow:loss = 0.18219, step = 701 (0.371 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.91381 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.914683 (0.035 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.915527 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.916346 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.917614 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.91791 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.918199 (0.036 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.918478 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.919196 (0.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.664\n",
      "INFO:tensorflow:train_accuracy = 0.919894 (0.041 sec)\n",
      "INFO:tensorflow:loss = 0.0421399, step = 801 (0.371 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.920573 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.921233 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.921875 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.922083 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.923109 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.924107 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.92508 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.926028 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.925 (0.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.249\n",
      "INFO:tensorflow:train_accuracy = 0.925926 (0.040 sec)\n",
      "INFO:tensorflow:loss = 0.00482497, step = 901 (0.385 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.926448 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.927334 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.928199 (0.041 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.928309 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.928416 (0.040 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.928879 (0.037 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.929688 (0.038 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.930477 (0.039 sec)\n",
      "INFO:tensorflow:train_accuracy = 0.93125 (0.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/mnist/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.126534.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-11-16:16:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist/model.ckpt-1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-126e86f7f6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-126e86f7f6c4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Evaluate the model and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_tfrecords_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluation results:\\n\\t%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[0;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    837\u001b[0m           \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m           config=self._session_config)\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m       _write_dict_to_summary(\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(unused_argv):\n",
    "    \n",
    "    # Create classifier\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "          model_fn=model_fn,\n",
    "          model_dir='/tmp/mnist',\n",
    "          params={})\n",
    "\n",
    "    # Set up training hook that logs the training accuracy every 100 steps.\n",
    "    tensors_to_log = {'train_accuracy': 'train_accuracy'}\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=10)\n",
    "\n",
    "    # Train the model\n",
    "    mnist_classifier.train(input_fn=lambda:train_input_fn(trn_tfrecords_file, FLAGS.batch_size),\n",
    "                           hooks=[logging_hook], max_steps=FLAGS.train_steps)\n",
    "\n",
    "    \n",
    "    # Evaluate the model and print results\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=lambda:train_input_fn(tst_tfrecords_file, FLAGS.batch_size))\n",
    "    print()\n",
    "    print('Evaluation results:\\n\\t%s' % eval_results)\n",
    "\n",
    "    # Export the model\n",
    "    image = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({'image': image})\n",
    "    mnist_classifier.export_savedmodel('/tmp/mnist_model/', input_fn)\n",
    "    \n",
    "#tf.estimator.Estimator.export_savedmodel()    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Define the arguments of the program\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch_size', default=32, type=int, help='batch size')\n",
    "    parser.add_argument('--train_steps', default=1000, type=int,\n",
    "                        help='number of training steps')\n",
    "\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    \n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf14]",
   "language": "python",
   "name": "conda-env-tf14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
