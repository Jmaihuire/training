{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa46c214d30>, '_task_id': 0, '_tf_random_seed': None, '_model_dir': '/tmp/mnist_model', '_master': '', '_service': None, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_is_chief': True, '_session_config': None, '_save_checkpoints_steps': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:train_accuracy = 0.140625\n",
      "INFO:tensorflow:step = 1, loss = 2.29284\n",
      "INFO:tensorflow:global_step/sec: 65.8884\n",
      "INFO:tensorflow:train_accuracy = 0.460938 (1.519 sec)\n",
      "INFO:tensorflow:step = 101, loss = 0.565832 (1.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.5162\n",
      "INFO:tensorflow:train_accuracy = 0.625 (1.212 sec)\n",
      "INFO:tensorflow:step = 201, loss = 0.233587 (1.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.76\n",
      "INFO:tensorflow:train_accuracy = 0.714844 (0.815 sec)\n",
      "INFO:tensorflow:step = 301, loss = 0.130011 (0.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.57\n",
      "INFO:tensorflow:train_accuracy = 0.76875 (0.816 sec)\n",
      "INFO:tensorflow:step = 401, loss = 0.145763 (0.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.589\n",
      "INFO:tensorflow:train_accuracy = 0.807292 (0.815 sec)\n",
      "INFO:tensorflow:step = 501, loss = 0.0883068 (0.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.138\n",
      "INFO:tensorflow:train_accuracy = 0.828125 (0.826 sec)\n",
      "INFO:tensorflow:step = 601, loss = 0.133691 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.989\n",
      "INFO:tensorflow:train_accuracy = 0.849609 (0.826 sec)\n",
      "INFO:tensorflow:step = 701, loss = 0.042739 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.181\n",
      "INFO:tensorflow:train_accuracy = 0.864583 (0.819 sec)\n",
      "INFO:tensorflow:step = 801, loss = 0.0651859 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.076\n",
      "INFO:tensorflow:train_accuracy = 0.875 (0.826 sec)\n",
      "INFO:tensorflow:step = 901, loss = 0.0853941 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.244\n",
      "INFO:tensorflow:train_accuracy = 0.880682 (0.899 sec)\n",
      "INFO:tensorflow:step = 1001, loss = 0.220372 (0.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.718\n",
      "INFO:tensorflow:train_accuracy = 0.889323 (0.829 sec)\n",
      "INFO:tensorflow:step = 1101, loss = 0.0974882 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.453\n",
      "INFO:tensorflow:train_accuracy = 0.895433 (0.830 sec)\n",
      "INFO:tensorflow:step = 1201, loss = 0.106239 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.913\n",
      "INFO:tensorflow:train_accuracy = 0.899554 (0.820 sec)\n",
      "INFO:tensorflow:step = 1301, loss = 0.155051 (0.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.553\n",
      "INFO:tensorflow:train_accuracy = 0.905208 (0.822 sec)\n",
      "INFO:tensorflow:step = 1401, loss = 0.0364096 (0.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.729\n",
      "INFO:tensorflow:train_accuracy = 0.911133 (0.829 sec)\n",
      "INFO:tensorflow:step = 1501, loss = 0.020146 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.699\n",
      "INFO:tensorflow:train_accuracy = 0.915441 (0.829 sec)\n",
      "INFO:tensorflow:step = 1601, loss = 0.046171 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.81\n",
      "INFO:tensorflow:train_accuracy = 0.916667 (0.828 sec)\n",
      "INFO:tensorflow:step = 1701, loss = 0.218409 (0.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.415\n",
      "INFO:tensorflow:train_accuracy = 0.919408 (0.810 sec)\n",
      "INFO:tensorflow:step = 1801, loss = 0.177265 (0.811 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1876 into /tmp/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0201572.\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz to /tmp/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz to /tmp/mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-08-07:06:41\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_model/model.ckpt-1876\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-08-07:06:42\n",
      "INFO:tensorflow:Saving dict for global step 1876: accuracy = 0.9832, global_step = 1876, loss = 0.0505907\n",
      "\n",
      "Evaluation results:\n",
      "\t{'accuracy': 0.98320001, 'global_step': 1876, 'loss': 0.050590701}\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_model/model.ckpt-1876\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/mnist_model_export/temp-b'1520492802'/saved_model.pb\"\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/tf14/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#  Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import dataset\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "\n",
    "class Model(object):\n",
    "  \"\"\"Class that defines a graph to recognize digits in the MNIST dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, data_format):\n",
    "    \"\"\"Creates a model for classifying a hand-written digit.\n",
    "    Args:\n",
    "      data_format: Either 'channels_first' or 'channels_last'.\n",
    "        'channels_first' is typically faster on GPUs while 'channels_last' is\n",
    "        typically faster on CPUs. See\n",
    "        https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "    \"\"\"\n",
    "    if data_format == 'channels_first':\n",
    "      self._input_shape = [-1, 1, 28, 28]\n",
    "    else:\n",
    "      assert data_format == 'channels_last'\n",
    "      self._input_shape = [-1, 28, 28, 1]\n",
    "\n",
    "    self.conv1 = tf.layers.Conv2D(\n",
    "        32, 5, padding='same', data_format=data_format, activation=tf.nn.relu)\n",
    "    self.conv2 = tf.layers.Conv2D(\n",
    "        64, 5, padding='same', data_format=data_format, activation=tf.nn.relu)\n",
    "    self.fc1 = tf.layers.Dense(1024, activation=tf.nn.relu)\n",
    "    self.fc2 = tf.layers.Dense(10)\n",
    "    self.dropout = tf.layers.Dropout(0.4)\n",
    "    self.max_pool2d = tf.layers.MaxPooling2D(\n",
    "        (2, 2), (2, 2), padding='same', data_format=data_format)\n",
    "\n",
    "  def __call__(self, inputs, training):\n",
    "    \"\"\"Add operations to classify a batch of input images.\n",
    "    Args:\n",
    "      inputs: A Tensor representing a batch of input images.\n",
    "      training: A boolean. Set to True to add operations required only when\n",
    "        training the classifier.\n",
    "    Returns:\n",
    "      A logits Tensor with shape [<batch_size>, 10].\n",
    "    \"\"\"\n",
    "    y = tf.reshape(inputs, self._input_shape)\n",
    "    y = self.conv1(y)\n",
    "    y = self.max_pool2d(y)\n",
    "    y = self.conv2(y)\n",
    "    y = self.max_pool2d(y)\n",
    "    y = tf.layers.flatten(y)\n",
    "    y = self.fc1(y)\n",
    "    y = self.dropout(y, training=training)\n",
    "    return self.fc2(y)\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "  \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "  model = Model(params['data_format'])\n",
    "  image = features\n",
    "  if isinstance(image, dict):\n",
    "    image = features['image']\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    logits = model(image, training=False)\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.PREDICT,\n",
    "        predictions=predictions,\n",
    "        export_outputs={\n",
    "            'classify': tf.estimator.export.PredictOutput(predictions)\n",
    "        })\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "    logits = model(image, training=True)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=tf.argmax(labels, axis=1), predictions=tf.argmax(logits, axis=1))\n",
    "    # Name the accuracy tensor 'train_accuracy' to demonstrate the\n",
    "    # LoggingTensorHook.\n",
    "    tf.identity(accuracy[1], name='train_accuracy')\n",
    "    tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        loss=loss,\n",
    "        train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    logits = model(image, training=False)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        loss=loss,\n",
    "        eval_metric_ops={\n",
    "            'accuracy':\n",
    "                tf.metrics.accuracy(\n",
    "                    labels=tf.argmax(labels, axis=1),\n",
    "                    predictions=tf.argmax(logits, axis=1)),\n",
    "        })\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  data_format = FLAGS.data_format\n",
    "  if data_format is None:\n",
    "    data_format = ('channels_first'\n",
    "                   if tf.test.is_built_with_cuda() else 'channels_last')\n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      model_dir=FLAGS.model_dir,\n",
    "      params={\n",
    "          'data_format': data_format\n",
    "      })\n",
    "\n",
    "  # Train the model\n",
    "  def train_input_fn():\n",
    "    # When choosing shuffle buffer sizes, larger sizes result in better\n",
    "    # randomness, while smaller sizes use less memory. MNIST is a small\n",
    "    # enough dataset that we can easily shuffle the full epoch.\n",
    "    ds = dataset.train(FLAGS.data_dir)\n",
    "    ds = ds.cache().shuffle(buffer_size=50000).batch(FLAGS.batch_size).repeat(\n",
    "        FLAGS.train_epochs)\n",
    "    (images, labels) = ds.make_one_shot_iterator().get_next()\n",
    "    return (images, labels)\n",
    "\n",
    "  # Set up training hook that logs the training accuracy every 100 steps.\n",
    "  tensors_to_log = {'train_accuracy': 'train_accuracy'}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=100)\n",
    "  mnist_classifier.train(input_fn=train_input_fn, hooks=[logging_hook])\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  def eval_input_fn():\n",
    "    return dataset.test(FLAGS.data_dir).batch(\n",
    "        FLAGS.batch_size).make_one_shot_iterator().get_next()\n",
    "\n",
    "  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "  print()\n",
    "  print('Evaluation results:\\n\\t%s' % eval_results)\n",
    "\n",
    "  # Export the model\n",
    "  if FLAGS.export_dir is not None:\n",
    "    image = tf.placeholder(tf.float32, [None, 28, 28])\n",
    "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'image': image,\n",
    "    })\n",
    "    mnist_classifier.export_savedmodel(FLAGS.export_dir, input_fn)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--batch_size',\n",
    "      type=int,\n",
    "      default=64,\n",
    "      help='Number of images to process in a batch')\n",
    "  parser.add_argument(\n",
    "      '--data_dir',\n",
    "      type=str,\n",
    "      default='/tmp/mnist_data',\n",
    "      help='Path to directory containing the MNIST dataset')\n",
    "  parser.add_argument(\n",
    "      '--model_dir',\n",
    "      type=str,\n",
    "      default='/tmp/mnist_model',\n",
    "      help='The directory where the model will be stored.')\n",
    "  parser.add_argument(\n",
    "      '--train_epochs', type=int, default=2, help='Number of epochs to train.')\n",
    "  parser.add_argument(\n",
    "      '--data_format',\n",
    "      type=str,\n",
    "      default=None,\n",
    "      choices=['channels_first', 'channels_last'],\n",
    "      help='A flag to override the data format used in the model. channels_first '\n",
    "      'provides a performance boost on GPU but is not always compatible '\n",
    "      'with CPU. If left unspecified, the data format will be chosen '\n",
    "      'automatically based on whether TensorFlow was built for CPU or GPU.')\n",
    "  parser.add_argument(\n",
    "      '--export_dir',\n",
    "      type=str,\n",
    "      default='/tmp/mnist_model_export',\n",
    "      help='The directory where the exported SavedModel will be stored.')\n",
    "\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf14]",
   "language": "python",
   "name": "conda-env-tf14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
